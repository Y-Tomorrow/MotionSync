day1
确定项目:复刻视频操作到游戏中
实现方法：人物姿态提取->（映射到火柴人）->动作分析->键鼠控制

day2
方法选择
姿态识别yolov8-pose
调用yolov8n-pose实现自动标定
姿态标定
    labelme（F） 无法体现可见点，不可见点，遮挡点
    COCO Annotator （T）查看自动标定结果，修正标定
准备几张数据集测试，仅作为功能需求测试，因为原先coco-pose数据集已经很完善，可以适应大部分场景

day3
COCO Annotator微调
生成json 转为txt，加入yolov8n-pose继续训练
无法成功推理图片
未标定人物框图bbox
重新加入标定

day4
修改自动标定标注出人物bbox
测试自动标定，效果较好
修改后生成新的json，转为txt拓展训练正常

day5
网页制作 接口导入（AI）
后端: Flask Web框架
前端: HTML5 + CSS3 + JavaScript
通信: RESTful API + AJAX
异步处理: Python threading

day6
网页功能测试
demo映射到火柴人

day7
深度估计尝试实现z轴映射（失败）

day8
学习GCN，ST-GCN

day9
时序深度学习模型 LSTM（双向识别）
直接训练关键点动作对应的wasd及空格键位代表移动和跳跃

day10
用ST-GCN识别动作

day11
将识别动作结果转为键盘响应


层级	   技术	                      用途
后端框架	Flask	                  Web 服务器、路由、API
并发处理	threading	              后台任务执行
通信机制	queue.Queue	              线程间数据传递
实时推送	SSE (Server-Sent Events)  关键点数据流式传输
图像处理	OpenCV (cv2)	          视频帧处理、编码
深度学习	Ultralytics YOLO	      姿态估计
3D 渲染	   Three.js	                 浏览器端 3D 火柴人
前端通信	EventSource API	          接收 SSE 数据流
图形绘制	Canvas API	              ROI 选择、关键点绘制
进程管理	subprocess	              启动外部脚本
