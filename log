day1
确定项目:复刻视频操作到游戏中
实现方法：人物姿态提取->（映射到火柴人）->动作分析->键鼠控制

day2
方法选择
姿态识别yolov8-pose
调用yolov8n-pose实现自动标定
姿态标定
    labelme（F） 无法体现可见点，不可见点，遮挡点
    COCO Annotator （T）查看自动标定结果，修正标定
准备几张数据集测试，仅作为功能需求测试，因为原先coco-pose数据集已经很完善，可以适应大部分场景

day3
COCO Annotator微调
生成json 转为txt，加入yolov8n-pose继续训练
无法成功推理图片
未标定人物框图bbox
重新加入标定

day4
修改自动标定标注出人物bbox
测试自动标定，效果较好
修改后生成新的json，转为txt拓展训练正常

day5
网页制作 接口导入（AI）
后端: Flask Web框架
前端: HTML5 + CSS3 + JavaScript
通信: RESTful API + AJAX
异步处理: Python threading

day6
网页功能测试
demo映射到火柴人

day7
深度估计尝试实现z轴映射（失败）

day8
学习GCN，ST-GCN

day9
时序深度学习模型 LSTM（双向识别）
直接训练关键点动作对应的wasd及空格键位代表移动和跳跃

day10
用ST-GCN识别动作
